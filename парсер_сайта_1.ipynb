{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cb4112",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "import re, time, random, requests, platform, subprocess, os\n",
    "from string import ascii_letters, whitespace\n",
    "import unicodedata\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed512256",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.6 Safari/605.1.15'}\n",
    "FQDN = 'https://s*****.**'\n",
    "responce = requests.get(FQDN)\n",
    "\n",
    "print(\"request denied\") if responce.status_code != 200 else print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0f8e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html(url, params=None):\n",
    "    r = requests.get(url, headers=header, params=params)\n",
    "    return r\n",
    "\n",
    "def open_file(path):\n",
    "    if platform.system() == \"Windows\":\n",
    "        os.startfile(path)\n",
    "    elif platform.system() == \"Darwin\":\n",
    "        subprocess.Popen([\"open\", path])\n",
    "    else:\n",
    "        subprocess.Popen([\"xdg-open\", path])\n",
    "\n",
    "def to_eng(text):\n",
    "    return (' '.join(re.findall(r'[A-z0-9.№]+', text))).replace('. ','').strip('.').strip()\n",
    "\n",
    "def to_rus(text):\n",
    "    return (' '.join(re.findall(r'[А-я0-9.№]+', text))).replace('. ','').strip('.').strip()\n",
    "\n",
    "def clean(text):\n",
    "    if any(letter.isalpha() for letter in text):\n",
    "        return text\n",
    "    else:\n",
    "        return ''\n",
    "            \n",
    "def post_proc(text: str):\n",
    "    text_eng = (' '.join(re.findall(r'[A-z0-9\\'äáàåãâčçÇČèéěÉğíóòöōôÓşśšŠúüÜýŽñßəıøł@&’.№]+', text)))\n",
    "    text_rus = (' '.join(re.findall(r'[А-я0-9ё.«»№]+', text)))\n",
    "    if any(letter.isalpha() for letter in text_eng):\n",
    "        pass\n",
    "    else:\n",
    "        text_eng = ''\n",
    "        \n",
    "    if any(letter.isalpha() for letter in text_rus):\n",
    "        pass\n",
    "    else:\n",
    "        text_rus = ''\n",
    "\n",
    "    text_eng = list(text_eng.split())\n",
    "    text_rus = list(text_rus.split())\n",
    "    \n",
    "    unique_words_eng = []\n",
    "    dupl_words_eng = []\n",
    "    unique_words_rus = []\n",
    "    dupl_words_rus = []\n",
    "    \n",
    "    for w in text_eng:\n",
    "        if w not in unique_words_eng:\n",
    "            unique_words_eng.append(w)\n",
    "        else:\n",
    "            if any(letter.isalpha() for letter in w):\n",
    "                dupl_words_eng.append(w)\n",
    "        \n",
    "    for w in text_rus:\n",
    "        if w not in unique_words_rus:\n",
    "            unique_words_rus.append(w)\n",
    "    unique_words_rus.extend(dupl_words_eng)\n",
    "    \n",
    "    clean_eng = ' '.join(unique_words_eng).strip().lstrip('.').strip().replace(' . ',' ')\n",
    "    clean_rus = ' '.join(unique_words_rus).strip().lstrip('.').strip().replace(' . ',' ')\n",
    "    return clean_eng, clean_rus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae0edf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def breeding_page(p_url:str):\n",
    "    '''\n",
    "    Web scraping breeding page\n",
    "    Example p_url: https://s****.**/catalog/type-4/?page=97\n",
    "    '''\n",
    "    response = get_html(p_url)\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    # название объекта\n",
    "    tittle_object = [e.text.strip() for e in soup.find_all('a', class_ = 'camp__title')]\n",
    "    # статус работы\n",
    "    status_object = [e.find('span', style = True).text if e.find('span', style = True) else 'Открыто' for e in soup.find_all('div', class_ = 'camp-min__head-name-inner')]\n",
    "    # ссылка на объект\n",
    "    url_object = [FQDN + e.get('href') for e in soup.find_all('a', class_ = 'camp__title')]\n",
    "    # страна объекта\n",
    "    country_object = [e.text.strip().split('\\n')[0] for e in soup.find_all('div', class_ = 'location')]\n",
    "    # город объекта\n",
    "    city_object = [e.text.strip().split('\\n')[-1] for e in soup.find_all('div', class_ = 'location')]\n",
    "    # рейтинг объекта\n",
    "    raiting_object = [e.text.strip() for e in soup.find_all('div', class_ = 'evaluation__rating')]\n",
    "    # количество отзывов на объект\n",
    "    response_object = [re.sub('\\D', '', e.text.strip().partition('отзывов')[0]) \n",
    "                       if 'отзывов' in e.text.strip() else 0 \n",
    "                       for e in soup.find_all('div', class_ = 'camp-min__head-rating')]\n",
    "    # cтоимость обучения\n",
    "    price_object = [e.text.strip().partition('от ')[-1].partition('Подать документы')[0].replace(' ','').replace('\\n','') \n",
    "                    if 'от ' in e.text.strip() else 'Нет данных' \n",
    "                    for e in soup.find_all('div', class_ = 'camp-min__head-rating')]\n",
    "    \n",
    "    \n",
    "    assert(len(tittle_object)==len(status_object)==len(url_object)==len(country_object)==len(city_object)==len(raiting_object)==len(response_object)==len(price_object)), 'Assert Error'\n",
    "    time.sleep(random.uniform(.6, 1.5))\n",
    "    \n",
    "    return tittle_object,status_object,url_object,country_object,city_object,raiting_object,response_object,price_object\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e860165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Главная\n",
    "FQDN = 'https://s****.**'\n",
    "response = get_html(FQDN)\n",
    "soup = BeautifulSoup(response.text, 'lxml')\n",
    "class_object = [e.text.strip() for e in soup.find_all('div', class_ = 'sect-institutions__title')]\n",
    "class_url = [[FQDN + e1.get('data-href') for e1 in e.find_all(attrs={'data-href':True})] for e in soup.find_all(attrs={\"class\": \"sect-institutions__box\"})][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4c2683",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for class_object_tag, class_url_tag in zip(class_object[:], class_url[:]):\n",
    "    response = get_html(class_url_tag)\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    last_page = int([e.text for e in soup.find_all('a', class_ = 'pagination__link')][-1])\n",
    "    \n",
    "    data = pd.DataFrame()\n",
    "    type_object = []\n",
    "    tittle_object = []\n",
    "    status_object = []\n",
    "    url_object = []\n",
    "    country_object = []\n",
    "    city_object = []\n",
    "    raiting_object = []\n",
    "    response_object = []\n",
    "    price_object = []\n",
    "\n",
    "    for num_page in range(last_page):\n",
    "        elem1, elem2, elem3, elem4, elem5, elem6, elem7,elem8 = breeding_page(class_url_tag +'?page=' + str(num_page+1))\n",
    "        tittle_object.extend(elem1)\n",
    "        status_object.extend(elem2)\n",
    "        url_object.extend(elem3)\n",
    "        country_object.extend(elem4)\n",
    "        city_object.extend(elem5)\n",
    "        raiting_object.extend(elem6)\n",
    "        response_object.extend(elem7)\n",
    "        price_object.extend(elem8)\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        print(class_url_tag +'?page=' + str(num_page+1))\n",
    "        print(len(elem1),len(elem2),len(elem3),len(elem4),len(elem5),len(elem6),len(elem7),len(elem8))\n",
    "    \n",
    "    type_object = [class_object_tag]*len(tittle_object)\n",
    "    print(len(tittle_object),len(status_object),len(url_object),len(country_object),len(city_object),len(raiting_object),len(response_object),len(price_object),len(type_object))\n",
    "    \n",
    "    data['Тип объекта'] = type_object\n",
    "    data['Полное название'] = tittle_object\n",
    "    data['Статус'] = status_object\n",
    "    data['Ссылка'] = url_object\n",
    "    data['Страна'] = country_object\n",
    "    data['Город'] = city_object\n",
    "    data['Оценка'] = raiting_object\n",
    "    data['Количество отзывов'] = response_object\n",
    "    data['Минимальная стоимость'] = price_object\n",
    "    data['Оценка'] = data['Оценка'].astype('float')\n",
    "    data['Количество отзывов'] = data['Количество отзывов'].astype('int32')\n",
    "    df = pd.concat([df, data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcfa546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# пост-процессинг\n",
    "# распарсим полные названия на eng/rus\n",
    "df['Полное название(eng)'] = df['Полное название'].apply(lambda x: post_proc(x)[0] if isinstance(x, str) else x)\n",
    "df['Полное название(rus)'] = df['Полное название'].apply(lambda x: post_proc(x)[1] if isinstance(x, str) else x)\n",
    "   \n",
    "# распарсим данные по стоимости,валюте,периоде\n",
    "df['Cтоимость(в цифрах)'] = df['Минимальная стоимость'].apply(lambda x: re.sub('\\D', '', x.split('/')[0].replace('.00','')) if x else None)\n",
    "df['Cтоимость(в цифрах)'] = pd.to_numeric(df['Cтоимость(в цифрах)'], downcast='signed', errors='coerce')\n",
    "df['Cтоимость(в цифрах)'] = df['Cтоимость(в цифрах)'].astype('Int64')\n",
    "df['Валюта'] = df['Минимальная стоимость'].apply(lambda x: x.split('/')[0].partition('.00')[-1] if '/' in x and '.00' in x else x)\n",
    "df['Период'] = df['Минимальная стоимость'].apply(lambda x: x.split('/')[-1] if '/' in x else x)\n",
    "\n",
    "df = df.reindex(columns=['Тип объекта','Полное название','Полное название(eng)','Полное название(rus)',\n",
    "                          'Статус','Ссылка','Страна','Город','Оценка','Количество отзывов',\n",
    "                          'Минимальная стоимость','Cтоимость(в цифрах)','Валюта','Период'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2ea026",
   "metadata": {},
   "outputs": [],
   "source": [
    "foundation = []\n",
    "age = []\n",
    "learning_type = []\n",
    "n_students = []\n",
    "programs = []\n",
    "placement = []\n",
    "rating = []\n",
    "advantage = []\n",
    "temp_count_n_stud = []\n",
    "temp_foundation = []\n",
    "count=0\n",
    "error = {}\n",
    "\n",
    "for p_url in df['Ссылка'][:].iteritems():\n",
    "    clear_output(wait=True)\n",
    "    print(p_url[1])\n",
    "    response = get_html(p_url[1])\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    count_f = count_age = count_l = count_n_stud = count_prog = count_place = count_rait = count_adv = 0\n",
    "    for e in soup.find_all('div',class_ = 'accordion__box'):\n",
    "        for e1 in e.find_all('li'):\n",
    "            if 'основан' in e1.text.strip().lower() and ':' in e1.text.strip():\n",
    "                count_f += 1\n",
    "                temp_foundation.append(e1.text.strip().split(':')[-1].strip())\n",
    "            if 'Возраст' in e1.text.strip() and (':' in e1.text.strip() or '–' in e1.text.strip()):\n",
    "                count_age += 1\n",
    "                age.append(unicodedata.normalize(\"NFKC\", e1.text.strip().split(':')[-1].strip()))\n",
    "            if ('Вид обучения' in e1.text.strip() \n",
    "                or 'Формы обучения' in e1.text.strip()) and ':' in e1.text.strip():\n",
    "                count_l += 1\n",
    "                learning_type.append(e1.text.strip().split(':')[-1].strip())\n",
    "            if 'количество' in e1.text.strip().lower() and ':' in e1.text.strip():\n",
    "                count_n_stud += 1\n",
    "                temp_count_n_stud.append(unicodedata.normalize(\"NFKC\", e1.text.strip().split(':')[-1].strip()))\n",
    "            if 'Программы' in e1.text.strip() and ':' in e1.text.strip():\n",
    "                count_prog += 1\n",
    "                programs.append(unicodedata.normalize(\"NFKC\", e1.text.strip().split(':')[-1].strip()))\n",
    "            if ('Размещение' in e1.text.strip() \n",
    "                or 'Тип проживания' in e1.text.strip()) and ':' in e1.text.strip():\n",
    "                count_place += 1\n",
    "                placement.append(unicodedata.normalize(\"NFKC\", e1.text.strip().split(':')[-1].strip()))\n",
    "            if 'Рейтинг' in e1.text.strip() and ':' in e1.text.strip():\n",
    "                count_rait += 1\n",
    "                rating.append(unicodedata.normalize(\"NFKC\", e1.text.strip().split(':')[-1].strip()))\n",
    "                \n",
    "        if len(temp_foundation) > 0:\n",
    "            foundation.append(temp_foundation[0])\n",
    "            temp_foundation = []\n",
    "            \n",
    "        if len(temp_count_n_stud) > 0:\n",
    "            n_students.append(temp_count_n_stud[0])\n",
    "            temp_count_n_stud = []\n",
    "            \n",
    "        break\n",
    "\n",
    "    if count_f == 0 and count_age == 0 and count_l == 0 and count_n_stud == 0 and count_prog == 0 \\\n",
    "    and count_place == 0 and count_rait == 0 and count_adv == 0:\n",
    "        for e in soup.find_all('div',class_ = 'accordion__box'):\n",
    "            for e1 in e.find_all('p'):\n",
    "                if 'основан' in e1.text.strip().lower() and ':' in e1.text.strip():\n",
    "                    count_f += 1\n",
    "                    temp_foundation.append(e1.text.strip().split(':')[-1].strip())\n",
    "                if 'Возраст' in e1.text.strip() and (':' in e1.text.strip() or '–' in e1.text.strip()):\n",
    "                    count_age += 1\n",
    "                    age.append(unicodedata.normalize(\"NFKC\", e1.text.strip().split(':')[-1].strip()))\n",
    "                if ('Вид обучения' in e1.text.strip() \n",
    "                    or 'Формы обучения' in e1.text.strip()) and ':' in e1.text.strip():\n",
    "                    count_l += 1\n",
    "                    learning_type.append(e1.text.strip().split(':')[-1].strip())\n",
    "                if 'количество' in e1.text.strip().lower() and ':' in e1.text.strip():\n",
    "                    count_n_stud += 1\n",
    "                    temp_count_n_stud.append(unicodedata.normalize(\"NFKC\", e1.text.strip().split(':')[-1].strip()))\n",
    "                if 'Программы' in e1.text.strip() and ':' in e1.text.strip():\n",
    "                    count_prog += 1\n",
    "                    programs.append(unicodedata.normalize(\"NFKC\", e1.text.strip().split(':')[-1].strip()))\n",
    "                if ('Размещение' in e1.text.strip() \n",
    "                    or 'Тип проживания' in e1.text.strip()) and ':' in e1.text.strip():\n",
    "                    count_place += 1\n",
    "                    placement.append(unicodedata.normalize(\"NFKC\", e1.text.strip().split(':')[-1].strip()))\n",
    "                if 'Рейтинг' in e1.text.strip() and ':' in e1.text.strip():\n",
    "                    count_rait += 1\n",
    "                    rating.append(unicodedata.normalize(\"NFKC\", e1.text.strip().split(':')[-1].strip()))\n",
    "                    \n",
    "            if len(temp_foundation) > 0:\n",
    "                foundation.append(temp_foundation[0])\n",
    "                temp_foundation = []\n",
    "                \n",
    "            if len(temp_count_n_stud) > 0:\n",
    "                n_students.append(temp_count_n_stud[0])\n",
    "                temp_count_n_stud = []\n",
    "                \n",
    "            break\n",
    "\n",
    "    # поиск дополнительных рейтинговых блоков\n",
    "    if count_rait == 0:\n",
    "        for e in soup.find_all('p'):\n",
    "            if 'Рейтинг' in e.text and ':' in e.text:\n",
    "                count_rait += 1\n",
    "                rating.append(unicodedata.normalize(\"NFKC\", e.find_next(\"ul\").text).strip().replace('\\n',' '))\n",
    "\n",
    "    # поиск дополнительных блоков с программами\n",
    "    if count_prog == 0:\n",
    "        for e in soup.find_all('h2',class_ = 'accordion__title active'):        \n",
    "            if 'Программы' in e.text:\n",
    "                dop_prog=[]\n",
    "                for e1 in e.find_all_next(\"span\",itemprop=\"name\"):\n",
    "                    dop_prog.append(e1.text)\n",
    "        dop_progs_text = ', '.join(dop_prog)\n",
    "        count_prog += 1\n",
    "        programs.append(dop_progs_text)\n",
    "            \n",
    "    # поиск блока Преимущества\n",
    "    for e in soup.find_all('h2',class_ = 'accordion__title active'):        \n",
    "        if 'Преимущества' in e.text:\n",
    "            count_adv += 1\n",
    "            adv = e.text.strip()\n",
    "            advantage.append(unicodedata.normalize(\"NFKC\", e.parent.text.strip().replace(adv,'').replace('\\n',' ').strip()))\n",
    "\n",
    "    if count_f == 0:\n",
    "        foundation.append('Нет данных')\n",
    "    if count_age == 0:\n",
    "        age.append('Нет данных')    \n",
    "    if count_l == 0:\n",
    "        learning_type.append('Нет данных')\n",
    "    if count_n_stud == 0:\n",
    "        n_students.append('Нет данных') \n",
    "    if count_prog == 0:\n",
    "        programs.append('Нет данных')                 \n",
    "    if count_place == 0:\n",
    "        placement.append('Нет данных')                     \n",
    "    if count_rait == 0:\n",
    "        rating.append('Нет данных')\n",
    "    if count_adv == 0:\n",
    "        advantage.append('Нет данных')  \n",
    "    \n",
    "    count+=1\n",
    "    print(len(foundation),len(age),len(learning_type),len(n_students),len(programs),len(placement),len(rating),len(advantage),count)\n",
    "    try:    \n",
    "        assert (len(foundation)==len(age)==len(learning_type)==len(n_students)==len(programs)==len(placement)==len(rating)==len(advantage)==count),'Assert Error!'\n",
    "    except:\n",
    "        max_value = max(len(foundation),len(age),len(learning_type),len(n_students),len(programs),len(placement),len(rating),len(advantage))\n",
    "        max_index = [len(foundation),len(age),len(learning_type),len(n_students),len(programs),len(placement),len(rating),len(advantage)].index(max_value)\n",
    "        error[p_url] = max_index\n",
    "\n",
    "        foundation = foundation[:count]\n",
    "        age = age[:count]\n",
    "        learning_type = learning_type[:count]\n",
    "        n_students = n_students[:count]\n",
    "        programs = programs[:count]\n",
    "        placement = placement[:count]\n",
    "        rating = rating[:count]\n",
    "        advantage = advantage[:count]\n",
    "    \n",
    "    time.sleep(random.uniform(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5156c1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Год основания'] = foundation\n",
    "df['Возраст обучающихся'] = age\n",
    "df['Вид обучения'] = learning_type\n",
    "df['Количество учащихся'] = n_students\n",
    "df['Программы обучения'] = programs\n",
    "df['Размещение'] = placement\n",
    "df['Рейтинг'] = rating\n",
    "df['Преимущества'] = advantage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4ab1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('_'.join(FQDN.split('/')[2].split('.')) + '.xlsx', \n",
    "                                engine_kwargs={'options': {'strings_to_urls': True}}) as writer:\n",
    "    df.to_excel(writer, sheet_name='Лист1', index=False)\n",
    "open_file('_'.join(FQDN.split('/')[2].split('.')) + '.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2194345b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
